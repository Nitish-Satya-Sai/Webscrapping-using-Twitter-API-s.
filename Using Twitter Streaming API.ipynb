{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "api_key = \"xxxxxxxxxxxxxxx\"\n",
    "api_key_secret =\"xxxxxxxxxxxxxxx\" \n",
    "access_token = \"xxxxxxxxxxxxxxx\"\n",
    "access_token_secret =\"xxxxxxxxxxxxxxx\" \n",
    "bearer_token = r\"xxxxxxxxxxxxxxx\"\n",
    "# Getting authentication done through our developer created app\n",
    "client = tweepy.Client(bearer_token, api_key, api_key_secret, access_token, access_token_secret)\n",
    "auth = tweepy.OAuth1UserHandler(api_key, api_key_secret, access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "class Tweets_Listener(tweepy.StreamingClient):\n",
    "    def on_connect(self):\n",
    "        print(\"connected successfully\")\n",
    "    stop_time=time.time()+30\n",
    "    tweets=[]\n",
    "    def on_tweet(self,tweet):\n",
    "        if tweet.referenced_tweets==None:\n",
    "            self.tweets.append(tweet.text)\n",
    "            #print(type(tweet.text))\n",
    "            time.sleep(0.5)\n",
    "        if(time.time()>self.stop_time):\n",
    "            #Just want to stop retrieving the tweets after 60seconds \n",
    "            self.disconnect()\n",
    "            print(\"Half minute completed\")\n",
    "#### creating object for our designed class\n",
    "stream_tweets_extractor = Tweets_Listener(bearer_token=bearer_token)\n",
    "keywords=[\"Michigan State University\"] #If we want, we can add more keywords\n",
    "for keyword in keywords:\n",
    "    #adding a rule, to extract only the tweets that contains keyword politics\n",
    "    stream_tweets_extractor.add_rules(tweepy.StreamRule(keyword)) \n",
    "#Here we make sure to discard the referenced tweets. re-tweets\n",
    "stream_tweets_extractor.filter(tweet_fields=[\"referenced_tweets\"])\n",
    "print(\"The number of tweets obtained in one minute time duration:\",\n",
    "      len(stream_tweets_extractor.tweets))\n",
    "#creating a DataFrame with list of tweets obtained from real-time twitter streams\n",
    "df_tweets = pd.DataFrame(stream_tweets_extractor.tweets,columns=[\"Tweets obtained in 60 seconds/ one minute\"])\n",
    "#Creating and storing the retrieved data in a json file.\n",
    "df_tweets.to_json(\"D:\\Michigan_State_University_Works\\CSE 482\\Exercises\\exercise-2\\msu.json\")\n",
    "## Retrieving data from json file, cross-checking the data which we stored in \"politics.json\" file\n",
    "df_tweets = pd.read_json(\"D:\\Michigan_State_University_Works\\CSE 482\\Exercises\\exercise-2\\msu.json\")\n",
    "#Just checking one tweet, whether politics keywords exists or not!!! Yes it is there\n",
    "df_tweets.iloc[0,0]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
